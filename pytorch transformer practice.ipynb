{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, emb_dim, q_dim, k_dim):\n",
    "        super().__init__()\n",
    "        self.Wq = nn.Linear(emb_dim, q_dim)\n",
    "        self.Wk = nn.Linear(emb_dim, k_dim)\n",
    "        self.Wv = nn.Linear(emb_dim, k_dim)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        Q = self.Wq(x)\n",
    "        K = self.Wk(z)\n",
    "        V = self.Wv(z)\n",
    "#         print(K.shape)\n",
    "        S = Q.bmm(K.transpose(1,2))\n",
    "        # uhh masking here\n",
    "#         print(S.shape)\n",
    "        sm = F.softmax(torch.div(S,torch.sqrt(torch.tensor(x.shape[-1]))),dim=-1)\n",
    "#         print(sm.shape)\n",
    "#         print(V.shape)\n",
    "        return sm.bmm(V)\n",
    "    \n",
    "class MHAttn(nn.Module):\n",
    "    def __init__(self, num_heads, emb_dim, q_dim, k_dim):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Attn(emb_dim, q_dim, k_dim) for _ in range(num_heads)])\n",
    "        self.Wo = nn.Linear(num_heads * k_dim, emb_dim)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        subAttns = torch.cat([h(x,z) for h in self.heads], dim=-1)\n",
    "        return self.Wo(subAttns)\n",
    "        \n",
    "# encoder is definitionally self-attn\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, z_dim, heads):\n",
    "        super().__init__()\n",
    "        self.attn = MHAttn(heads, emb_dim, z_dim, z_dim)\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.ff1 = nn.Linear(emb_dim,emb_dim)\n",
    "        self.ff2 = nn.Linear(emb_dim,emb_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = z + self.attn(z,z)\n",
    "        z = self.ln1(z)\n",
    "        z = z + self.ff2(F.relu(self.ff1(z)))\n",
    "        return self.ln2(z)\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, x_dim, z_dim, heads):\n",
    "        super().__init__()\n",
    "        self.attn = MHAttn(heads, emb_dim, x_dim, z_dim)\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.ln3 = nn.LayerNorm(emb_dim)\n",
    "        self.ff1 = nn.Linear(emb_dim,emb_dim)\n",
    "        self.ff2 = nn.Linear(emb_dim,emb_dim)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        x = x + self.attn(x,x)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.attn(x,z)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.ff2(F.relu(self.ff1(x)))\n",
    "        return self.ln3(x)\n",
    "        \n",
    "# review this\n",
    "\n",
    "class EDTransformer(nn.Module):\n",
    "    def __init__(self, embs, pos, emb_dim, x_dim, z_dim, heads, enc_blocks, dec_blocks, out_dim):\n",
    "        # needs embedding matrix\n",
    "        # garbage for now\n",
    "        # positional embedding scheme\n",
    "        # softmax FF at the end\n",
    "        super().__init__()\n",
    "        self.addpos = pos\n",
    "        self.emb = embs\n",
    "        self.enc_blocks = enc_blocks\n",
    "        self.dec_blocks = dec_blocks\n",
    "        self.encoderBlocks = nn.ModuleList(\n",
    "            [EncoderBlock(emb_dim, x_dim, heads) for _ in range(enc_blocks)]\n",
    "        )\n",
    "        self.decoderBlocks = nn.ModuleList(\n",
    "            [DecoderBlock(emb_dim, x_dim, z_dim, heads) for _ in range(dec_blocks)]\n",
    "        )\n",
    "        self.ff1 = nn.Linear(emb_dim, 1)\n",
    "        self.ff2 = nn.Linear(emb_dim, out_dim)\n",
    "\n",
    "    def forward(self, x,z):\n",
    "        # embed + pos\n",
    "        # if emb is not None, x better be an embedding already\n",
    "        if self.emb is not None:\n",
    "            x = self.emb(x)\n",
    "            z = self.emb(z)\n",
    "        # ! positions are encoded s, b, e\n",
    "        print(\"after emb layer\")\n",
    "        print(x.shape)\n",
    "        x = self.addpos(x.permute(1,0,2)).permute(1,0,2)\n",
    "        z = self.addpos(z.permute(1,0,2)).permute(1,0,2)\n",
    "        # loop through encoder blocks\n",
    "        for i in range(self.enc_blocks):\n",
    "            z = self.encoderBlocks[i](z)\n",
    "        # loop through decoder blocks\n",
    "        for i in range(self.dec_blocks):\n",
    "            x = self.decoderBlocks[i](x, z)\n",
    "        # FF and softmax\n",
    "        print(\"after decoder\")\n",
    "        print(x.shape)\n",
    "        x = self.ff1(x)\n",
    "        print(\"after ff1 (emb->1)\")\n",
    "        print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        print(\"after flatten\")\n",
    "        print(x.shape)\n",
    "        return F.softmax(self.ff2(x), dim=-1)\n",
    "    \n",
    "class posEncoding(nn.Module):\n",
    "    def __init__(self, model_dim, dropout, maxlen):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        position = torch.arange(maxlen).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_dim, 2) * (-math.log(10000.0)/model_dim))\n",
    "#         print(\"position.shape\")\n",
    "#         print(position.shape)\n",
    "#         print(\"div_term.shape\")\n",
    "#         print(div_term.shape)\n",
    "#         print(\"model_dim\")\n",
    "#         print(model_dim)\n",
    "        pe = torch.zeros(maxlen, 1, model_dim)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "#         print(self.pe.shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"x.shape\")\n",
    "        print(x.shape)\n",
    "        print(\"self.pe[:x.shape[0]].shape\")\n",
    "        print(self.pe[:x.shape[0]].shape)\n",
    "        x = x + self.pe[:x.shape[0]]\n",
    "        return x #self.dropout(x)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exAttn = Attn(256, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence of 8 words\n",
    "x = torch.randn(1,8,256)\n",
    "# seq of 10\n",
    "z = torch.randn(1,10,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three seqs of 8 words\n",
    "x = torch.randn(3,8,256)\n",
    "# three seqs of 10\n",
    "z = torch.randn(3,10,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = exAttn(x,x)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exMHA = MHAttn(8, 256, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhres = exMHA(x,x)\n",
    "mhres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exEB = EncoderBlock(256, 32, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebres = exEB(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exDB = DecoderBlock(256, 32, 32, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbres = exDB(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exPE2 = posEncoding(256, 0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exEDT = EDTransformer(None, exPE2, 256, 32, 32, 8, 3,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after emb layer\n",
      "torch.Size([3, 8, 256])\n",
      "x.shape\n",
      "torch.Size([8, 3, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([8, 1, 256])\n",
      "x.shape\n",
      "torch.Size([10, 3, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([10, 1, 256])\n",
      "after decoder\n",
      "torch.Size([3, 8, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([3, 8, 1])\n",
      "after flatten\n",
      "torch.Size([3, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x8 and 256x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-251956cf0e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medtres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexEDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-171b8f969f90>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after flatten\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mposEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x8 and 256x1)"
     ]
    }
   ],
   "source": [
    "edtres = exEDT(x,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edtres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1fe7519c6369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medtres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'edtres' is not defined"
     ]
    }
   ],
   "source": [
    "edtres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after emb layer\n",
      "torch.Size([2, 8, 256])\n",
      "x.shape\n",
      "torch.Size([8, 2, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([8, 1, 256])\n",
      "x.shape\n",
      "torch.Size([10, 2, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([10, 1, 256])\n",
      "after decoder\n",
      "torch.Size([2, 8, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([2, 8, 1])\n",
      "after flatten\n",
      "torch.Size([2, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x8 and 256x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-576514dfb76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexEDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-171b8f969f90>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after flatten\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mposEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x8 and 256x1)"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(exEDT, [(8,256),(10,256)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST(\"./mnist\", download=True)\n",
    "mnistVal = torchvision.datasets.MNIST(\"./mnist\", train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "from collections import Iterable\n",
    "train_iter = IMDB(split='train')\n",
    "val_iter = IMDB(split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imdb csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mentioned watching Oz episode hoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production . The filming te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonderful way spend time hot summer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically family little boy Jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love Time Money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           processed  label\n",
       "0  One reviewer mentioned watching Oz episode hoo...      1\n",
       "1  A wonderful little production . The filming te...      1\n",
       "2  I thought wonderful way spend time hot summer ...      1\n",
       "3  Basically family little boy Jake think zombie ...      0\n",
       "4  Petter Mattei Love Time Money visually stunnin...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('imdb_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mentioned watching Oz episode hoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production . The filming te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonderful way spend time hot summer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically family little boy Jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love Time Money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought movie right good job . It creative o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot , bad dialogue , bad acting , idiotic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I Catholic taught parochial elementary school ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I going disagree previous comment side Maltin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects Star Trek movie high art , fan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               processed  label\n",
       "0      One reviewer mentioned watching Oz episode hoo...      1\n",
       "1      A wonderful little production . The filming te...      1\n",
       "2      I thought wonderful way spend time hot summer ...      1\n",
       "3      Basically family little boy Jake think zombie ...      0\n",
       "4      Petter Mattei Love Time Money visually stunnin...      1\n",
       "...                                                  ...    ...\n",
       "49995  I thought movie right good job . It creative o...      1\n",
       "49996  Bad plot , bad dialogue , bad acting , idiotic...      0\n",
       "49997  I Catholic taught parochial elementary school ...      0\n",
       "49998  I going disagree previous comment side Maltin ...      0\n",
       "49999  No one expects Star Trek movie high art , fan ...      0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['token_length'] = df.processed.apply(lambda x: len(x.split()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'reviewer',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'Oz',\n",
       " 'episode',\n",
       " 'hooked',\n",
       " '.',\n",
       " 'They',\n",
       " 'right']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df.processed.values\n",
    "words = ' '.join(reviews)\n",
    "words = words.split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "ctr = Counter(words)\n",
    "vocab = sorted(ctr, key=ctr.get, reverse=True)\n",
    "int2word = dict(enumerate(vocab, 1))\n",
    "int2word[0] = '<PAD>'\n",
    "word2int = {word: id for id, word in int2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exEMB = nn.Embedding(len(vocab), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exEMB(torch.ones(1, dtype=torch.long)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 27679.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "rev_enc = [[word2int[word] for word in review.split()] for review in tqdm(reviews)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  191,  1083,   930,    81,  3724,   186,  3030,     1,   118,\n",
       "          114],\n",
       "       [   47,   328,    59,   244,     1,     7,  1267,  1608, 17875,\n",
       "            4],\n",
       "       [    3,    95,   328,    30,  1041,    13,   845,  1774,  2633,\n",
       "            2],\n",
       "       [ 2408,   136,    59,   241,  3230,    37,   650,  4298,   583,\n",
       "          882],\n",
       "       [70982, 10566,  1081,  1941,  7538,  2280,  1313,     6,    46,\n",
       "            1],\n",
       "       [ 2795,     4,    13,   368,     5,     2,    17, 42503,     2,\n",
       "         2952],\n",
       "       [    3,   197,    18,    10,    21, 12517,  1904, 55922,   121,\n",
       "         5112],\n",
       "       [   14,    31,   427,     2,  1342,  4021,   165,    34,  2960,\n",
       "            1],\n",
       "       [47893,   980,   359,     6,     3,   180,   776,    81,     6,\n",
       "            1],\n",
       "       [   64,    10,   125,  2269,  5606,  1980,    10,     5,     1,\n",
       "           64]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def pad_features(reviews, pad_id, seq_length=128):\n",
    "    # features = np.zeros((len(reviews), seq_length), dtype=int)\n",
    "    features = np.full((len(reviews), seq_length), pad_id, dtype=int)\n",
    "\n",
    "    for i, row in enumerate(reviews):\n",
    "        # if seq_length < len(row) then review will be trimmed\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features\n",
    "\n",
    "seq_length = 256\n",
    "features = pad_features(rev_enc, pad_id=word2int['<PAD>'], seq_length=seq_length)\n",
    "\n",
    "assert len(features) == len(rev_enc)\n",
    "assert len(features[0]) == seq_length\n",
    "\n",
    "features[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.label.to_numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shapes:\n",
      "===============\n",
      "Train set: (37500, 256)\n",
      "Validation set: (12500, 256)\n",
      "Test set: (0, 256)\n"
     ]
    }
   ],
   "source": [
    "train_size = .75   # we will use 80% of whole data as train set\n",
    "val_size = 1      # and we will use 50% of test set as validation set\n",
    "\n",
    "# make train set\n",
    "split_id = int(len(features) * train_size)\n",
    "train_x, remain_x = features[:split_id], features[split_id:]\n",
    "train_y, remain_y = labels[:split_id], labels[split_id:]\n",
    "\n",
    "# make val and test set\n",
    "split_val_id = int(len(remain_x) * val_size)\n",
    "val_x, test_x = remain_x[:split_val_id], remain_x[split_val_id:]\n",
    "val_y, test_y = remain_y[:split_val_id], remain_y[split_val_id:]\n",
    "\n",
    "# print out the shape\n",
    "print('Feature Shapes:')\n",
    "print('===============')\n",
    "print('Train set: {}'.format(train_x.shape))\n",
    "print('Validation set: {}'.format(val_x.shape))\n",
    "print('Test set: {}'.format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "])\n",
    "\n",
    "traindata, trainlabels = zip(*[(transform(x[0])/255.0, x[1]) for x in mnist])\n",
    "valdata, vallabels = zip(*[(transform(x[0])/255.0, x[1]) for x in mnistVal])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "])\n",
    "\n",
    "traindata, trainlabels = zip(*[(transform(x[0])/255.0, x[1]) for x in mnist])\n",
    "valdata, vallabels = zip(*[(transform(x[0])/255.0, x[1]) for x in mnistVal])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainlabels))\n",
    "len(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trainlabels[0])\n",
    "# print(traindata[0])\n",
    "valdata = torch.cat(valdata)\n",
    "vallabels = torch.cat([torch.tensor([y]) for y in vallabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainlabels[0])\n",
    "print(traindata[0])\n",
    "traindata = torch.cat(traindata)\n",
    "trainlabels = torch.cat([torch.tensor([y]) for y in trainlabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(traindata, trainlabels)\n",
    "val_ds = TensorDataset(valdata, vallabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### back to imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch size\n",
    "batch_size = 128\n",
    "\n",
    "# create tensor datasets\n",
    "trainset = TensorDataset(torch.from_numpy(train_x[:128*8]), torch.from_numpy(train_y[:128*8]).to(torch.float32))\n",
    "validset = TensorDataset(torch.from_numpy(val_x[:128*4]), torch.from_numpy(val_y[:128*4]).to(torch.float32))\n",
    "# testset = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = DataLoader(trainset, shuffle=False, batch_size=batch_size)\n",
    "valloader = DataLoader(validset, shuffle=False, batch_size=batch_size)\n",
    "# testloader = DataLoader(testset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exEMB = nn.Embedding(len(vocab), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exPE2 = posEncoding(256, 0, 10000)\n",
    "lmaoOhLawd = EDTransformer(exEMB, exPE2, 256, 4, 4, 7, 3,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, b, e order\n",
    "# exPE2(torch.ones(28,1,28)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo: train with text data (quick)\n",
    "### next: LC babyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "val loss epoch  0 : tensor(185.1562)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "val loss epoch  1 : tensor(185.1562)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "val loss epoch  2 : tensor(185.1562)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "val loss epoch  3 : tensor(185.1562)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(0.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128, 1])\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "after emb layer\n",
      "torch.Size([128, 256, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "x.shape\n",
      "torch.Size([256, 128, 256])\n",
      "self.pe[:x.shape[0]].shape\n",
      "torch.Size([256, 1, 256])\n",
      "after decoder\n",
      "torch.Size([128, 256, 256])\n",
      "after ff1 (emb->1)\n",
      "torch.Size([128, 256, 1])\n",
      "after flatten\n",
      "torch.Size([128, 256])\n",
      "val loss epoch  4 : tensor(185.1562)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "opt = optim.Adagrad(lmaoOhLawd.parameters())\n",
    "loss_func = F.binary_cross_entropy\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for xtb, ytb in trainloader:\n",
    "        print(xtb.shape)\n",
    "        preds = lmaoOhLawd(xtb, xtb)\n",
    "        print(preds.shape)\n",
    "        print(ytb[0])\n",
    "        print(preds[0])\n",
    "        loss = loss_func(preds.squeeze().to(torch.float32), ytb.to(torch.float32))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        currvalloss = sum([loss_func(lmaoOhLawd(xtb, xtb).squeeze(), ytb) for xtb, ytb in valloader])\n",
    "        print(\"val loss epoch \", i, \":\", currvalloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
