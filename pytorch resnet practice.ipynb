{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "filename = \"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (PATH / filename).exists():\n",
    "        content = requests.get(url + filename).content\n",
    "        (PATH / filename).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / filename).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.normal(0, 1, size=(784, 10)) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb)  # predictions\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        #         set_trace()\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the typical loop\n",
    "# model, opt = get_model()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for xb, yb in train_dl:\n",
    "#         pred = model(xb)\n",
    "#         loss = loss_func(pred, yb)\n",
    "\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "\n",
    "# print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resNetBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, ds):\n",
    "        super().__init__()\n",
    "        #downsample means stride == 2, else 1\n",
    "        if ds:\n",
    "            self.conv1 = nn.Conv2d(channels_in, channels_out, 3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(channels_in, channels_out, 1, stride=2),\n",
    "                nn.BatchNorm2d(channels_out)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Identity()\n",
    "            \n",
    "        self.conv2 = nn.Conv2d(channels_out, channels_out, 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels_out)\n",
    "        self.bn2 = nn.BatchNorm2d(channels_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "#         print(x.shape)\n",
    "#         print(shortcut.shape)\n",
    "        x = x + shortcut\n",
    "        return F.relu(self.bn2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resNet(nn.Module):\n",
    "    def __init__(self, channels_in, rnb_class, output_dim=10):\n",
    "        super().__init__()\n",
    "        self.l0 = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, 64, 7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            rnb_class(64, 64, False),\n",
    "            rnb_class(64, 64, False)\n",
    "        )\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "            rnb_class(64, 128, True),\n",
    "            rnb_class(128, 128, False)\n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            rnb_class(128, 256, True),\n",
    "            rnb_class(256, 256, False)\n",
    "        )\n",
    "        self.l4 = nn.Sequential(\n",
    "            rnb_class(256, 512, True),\n",
    "            rnb_class(512, 512, False)\n",
    "        )\n",
    "        #Adaptive\n",
    "        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(256, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l0(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "#         x = self.l4(x)\n",
    "        x = self.gap(x)\n",
    "#         print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "#         print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRN = resNet(1, resNetBlock, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
      "         MaxPool2d-2             [-1, 64, 7, 7]               0\n",
      "       BatchNorm2d-3             [-1, 64, 7, 7]             128\n",
      "              ReLU-4             [-1, 64, 7, 7]               0\n",
      "          Identity-5             [-1, 64, 7, 7]               0\n",
      "            Conv2d-6             [-1, 64, 7, 7]          36,928\n",
      "       BatchNorm2d-7             [-1, 64, 7, 7]             128\n",
      "            Conv2d-8             [-1, 64, 7, 7]          36,928\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "      BatchNorm2d-10             [-1, 64, 7, 7]             128\n",
      "      resNetBlock-11             [-1, 64, 7, 7]               0\n",
      "         Identity-12             [-1, 64, 7, 7]               0\n",
      "           Conv2d-13             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-14             [-1, 64, 7, 7]             128\n",
      "           Conv2d-15             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
      "      BatchNorm2d-17             [-1, 64, 7, 7]             128\n",
      "      resNetBlock-18             [-1, 64, 7, 7]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]           8,320\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "           Conv2d-21            [-1, 128, 4, 4]          73,856\n",
      "      BatchNorm2d-22            [-1, 128, 4, 4]             256\n",
      "           Conv2d-23            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-24            [-1, 128, 4, 4]             256\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "      resNetBlock-26            [-1, 128, 4, 4]               0\n",
      "         Identity-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "           Conv2d-30            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-31            [-1, 128, 4, 4]             256\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "      resNetBlock-33            [-1, 128, 4, 4]               0\n",
      "           Conv2d-34            [-1, 256, 2, 2]          33,024\n",
      "      BatchNorm2d-35            [-1, 256, 2, 2]             512\n",
      "           Conv2d-36            [-1, 256, 2, 2]         295,168\n",
      "      BatchNorm2d-37            [-1, 256, 2, 2]             512\n",
      "           Conv2d-38            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "      BatchNorm2d-40            [-1, 256, 2, 2]             512\n",
      "      resNetBlock-41            [-1, 256, 2, 2]               0\n",
      "         Identity-42            [-1, 256, 2, 2]               0\n",
      "           Conv2d-43            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-44            [-1, 256, 2, 2]             512\n",
      "           Conv2d-45            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-46            [-1, 256, 2, 2]             512\n",
      "      BatchNorm2d-47            [-1, 256, 2, 2]             512\n",
      "      resNetBlock-48            [-1, 256, 2, 2]               0\n",
      "AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0\n",
      "           Linear-50                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 2,783,114\n",
      "Trainable params: 2,783,114\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.86\n",
      "Params size (MB): 10.62\n",
      "Estimated Total Size (MB): 11.48\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(myRN, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.reshape(x_train, (50000, 1,28,28)).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = torch.reshape(x_valid, (x_valid.shape[0], 1,28,28)).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset as TDS\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TDS(x_train[:32*60], y_train[:32*60])\n",
    "val_ds = TDS(x_valid[:32*10], y_valid[:32*10])\n",
    "\n",
    "train_ds = DataLoader(train_ds, batch_size=32)\n",
    "val_ds = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "# our model\n",
    "myRN\n",
    "\n",
    "opt = torch.optim.AdamW(myRN.parameters())\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numepochs = 10\n",
    "# for i in range(numepochs):\n",
    "#     myRN.train()\n",
    "#     tls = 0\n",
    "#     for xb, yb in train_ds:\n",
    "# #         print(xb.shape)\n",
    "#         preds = myRN(xb)\n",
    "# #         _, preds = torch.max(out.data, 1)\n",
    "# #         print(preds.shape)\n",
    "#         loss = loss_func(preds, yb)\n",
    "#         tls += loss.item()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "#     print(\"training loss\")\n",
    "#     print(tls)\n",
    "#     # val\n",
    "#     myRN.eval()\n",
    "#     with torch.no_grad(): # xbv, ybv in val_ds:))\n",
    "#         loss2 = sum(loss_func(myRN(xbv), ybv) for xbv, ybv in val_ds)\n",
    "#         print(\"Val loss epoch\", i, \":\", loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss\n",
      "35.18148212879896\n",
      "Val acc epoch 0 :\n",
      "tensor(0.9219)\n",
      "Val loss epoch 0 : tensor(5.2100)\n",
      "training loss\n",
      "10.280327830463648\n",
      "Val acc epoch 1 :\n",
      "tensor(0.9375)\n",
      "Val loss epoch 1 : tensor(2.9550)\n",
      "training loss\n",
      "6.072369011119008\n",
      "Val acc epoch 2 :\n",
      "tensor(0.8906)\n",
      "Val loss epoch 2 : tensor(4.0395)\n",
      "training loss\n",
      "4.167758401017636\n",
      "Val acc epoch 3 :\n",
      "tensor(0.8875)\n",
      "Val loss epoch 3 : tensor(3.5296)\n",
      "training loss\n",
      "3.679632104933262\n",
      "Val acc epoch 4 :\n",
      "tensor(0.8969)\n",
      "Val loss epoch 4 : tensor(3.9238)\n",
      "training loss\n",
      "2.9543117783032358\n",
      "Val acc epoch 5 :\n",
      "tensor(0.9187)\n",
      "Val loss epoch 5 : tensor(2.8310)\n",
      "training loss\n",
      "2.290273612132296\n",
      "Val acc epoch 6 :\n",
      "tensor(0.9563)\n",
      "Val loss epoch 6 : tensor(1.9087)\n",
      "training loss\n",
      "1.2824750032741576\n",
      "Val acc epoch 7 :\n",
      "tensor(0.9344)\n",
      "Val loss epoch 7 : tensor(1.9509)\n",
      "training loss\n",
      "0.8547915040398948\n",
      "Val acc epoch 8 :\n",
      "tensor(0.9500)\n",
      "Val loss epoch 8 : tensor(1.7844)\n",
      "training loss\n",
      "0.9159827973344363\n",
      "Val acc epoch 9 :\n",
      "tensor(0.8969)\n",
      "Val loss epoch 9 : tensor(3.1752)\n"
     ]
    }
   ],
   "source": [
    "numepochs = 10\n",
    "for i in range(numepochs):\n",
    "    myRN.train()\n",
    "    tls = 0\n",
    "    for xb, yb in train_ds:\n",
    "#         print(xb.shape)\n",
    "        preds = myRN(xb)\n",
    "#         _, preds = torch.max(out.data, 1)\n",
    "#         print(preds.shape)\n",
    "        loss = loss_func(preds, yb)\n",
    "        tls += loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print(\"training loss\")\n",
    "    print(tls)\n",
    "    # val\n",
    "    myRN.eval()\n",
    "    with torch.no_grad(): # xbv, ybv in val_ds:))\n",
    "        valpreds, actual = zip(*[(myRN(xbv), ybv) for xbv, ybv in val_ds])\n",
    "        valpreds = torch.argmax(torch.cat(valpreds), dim=1)\n",
    "        print(\"Val acc epoch\", i, \":\")        \n",
    "        print(sum([p == a for p,a in zip(valpreds, torch.cat(actual))])/(val_ds.batch_size * len(val_ds)))\n",
    "        loss2 = sum(loss_func(myRN(xbv), ybv) for xbv, ybv in val_ds)\n",
    "        print(\"Val loss epoch\", i, \":\", loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6969)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # xbv, ybv in val_ds:))\n",
    "    valpreds, actual = zip(*[(myRN(xbv), ybv) for xbv, ybv in val_ds])\n",
    "    valpreds = torch.argmax(torch.cat(valpreds), dim=1)\n",
    "    print(sum([p == a for p,a in zip(valpreds, torch.cat(actual))])/(val_ds.batch_size * len(val_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 4, 4, 4, 4, 4, 3, 8, 4, 5, 4, 3, 8, 4, 8, 4, 5, 0, 5, 9, 7, 4, 1,\n",
      "        4, 4, 0, 4, 2, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(valpreds[0],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valpreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(valpreds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(actual).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.batch_size * len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
